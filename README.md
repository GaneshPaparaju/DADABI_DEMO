
# DADABI_DEMO ğŸ“Š  
### Data Engineering Practice & Project Implementation Repository

## ğŸ“Œ Overview
This repository contains individual and course workshop projects implemented using Azure Data Factory (ADF), focusing on building and testing scalable data pipelines, dataflows, and end-to-end data engineering solutions.  
It includes real-world datasets such as:
- **Seattle Pet License Data**
- **NYPD Complaint Data**

The aim of this repo is to demonstrate practical skills in data ingestion, transformation, staging, and loading into Snowflake, along with cleaning and pipeline orchestration using ADF.

---

## ğŸ“‚ Repository Structure
```
DADABI_DEMO/
â”‚
â”œâ”€â”€ dataflow/               # Data transformation logic using ADF Mapping Data Flows
â”œâ”€â”€ dataset/                # Dataset references for source and sink data
â”œâ”€â”€ factory/                # Azure Data Factory template
â”œâ”€â”€ integrationRuntime/     # Runtime configurations for ADF execution
â”œâ”€â”€ linkedService/          # Linked service definitions for Blob Storage and Snowflake
â”œâ”€â”€ pipeline/               # Orchestration pipelines (e.g., ingestion, cleaning, loading)
â”œâ”€â”€ publish_config.json     # ADF ARM deployment configuration
â””â”€â”€ main                    # Entry trigger or utility file
```

---

## ğŸ› ï¸ Projects Covered

### ğŸ“ Seattle Pet License Dataset
- **Objective**: Clean and transform pet license data for analysis.
- **Tasks Performed**:
  - Removing nulls and invalid records
  - Standardizing breed and species categories
  - Enriching data with geolocation details (ZIP code level)
  - Loading into Snowflake for dashboard/report use

### ğŸ“ NYPD Complaint Dataset
- **Objective**: Process and analyze crime complaint data from NYC Open Data.
- **Tasks Performed**:
  - Standardization of date and complaint type fields
  - Handling malformed characters and nulls
  - Creating a dimensional data model (Fact_Crime, Dim_Date, Dim_Location)
  - Loading transformed tables into Snowflake

---

## ğŸ”„ Process Flow
1. **Raw Data Ingestion** â†’ Azure Blob Storage  
2. **Cleaning & Transformation** â†’ Mapping Dataflows in ADF  
3. **Staging/Loading** â†’ Snowflake  
4. **Monitoring & Orchestration** â†’ Pipelines and Integration Runtime  

---

## ğŸ§° Tools & Technologies
- Azure Data Factory (ADF)
- Azure Blob Storage
- Snowflake
- Power BI (optional dashboarding layer)
- JSON-based ADF templates

---

## ğŸ’¡ Key Learnings
- Practiced building modular pipelines and reusable templates.
- Understood real-world data cleaning challenges and transformation logic.
- Gained expertise in linking cloud storage to Snowflake via ADF.
- Built foundational patterns for future enterprise-grade data solutions.

---

## ğŸ‘¨â€ğŸ’» Author
- **Ganesh Paparaju**

---

## ğŸ“¬ Contact
Feel free to explore or fork the repository.  
For collaboration or feedback, connect via GitHub or LinkedIn.
